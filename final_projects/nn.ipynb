{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Gf3WF6BZte11"
      },
      "outputs": [],
      "source": [
        "#Names: Kyle, Bekhruz, R\n",
        "#DO NOT EDIT THIS PART#\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# GPUs are 3x faster than CPU. Better to use if it is available \n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Define Loss Function\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "# This function returns the number of parameters in the model\n",
        "def num_params(model):\n",
        "  return sum([p.numel() for p in model.parameters()])\n",
        "\n",
        "# Define a Training Function. This function will: compute the forward pass, backpropagate,\n",
        "# update the weights, and repeat the steps for a given number of epochs. At each epoch, \n",
        "# it will output the training loss and test loss at every step\n",
        "def train(epochs, model, trainloader, testloader, optimizer, loss_function):\n",
        "  for epoch in range(epochs):\n",
        "    loss_epoch = np.array([])\n",
        "    train_correct, train_total = 0, 0\n",
        "    test_correct, test_total = 0, 0\n",
        "\n",
        "    for data, labels in trainloader:\n",
        "      # convert into GPU objects if needed\n",
        "      input_data = data.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      # forward pass\n",
        "      predict = model(input_data)\n",
        "      \n",
        "      # backward pass\n",
        "      loss = loss_function(predict, labels)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "\n",
        "      # update parameters (weights and biases)\n",
        "      optimizer.step()\n",
        "\n",
        "      # store progress\n",
        "      loss_epoch = np.append(loss_epoch, loss.item())\n",
        "\n",
        "    # evaluate test accuracy\n",
        "    for data, labels in testloader:\n",
        "      input_data = data.to(device)\n",
        "      labels = labels.to(device)\n",
        "      predict = model(input_data)\n",
        "      for i, out in enumerate(predict):\n",
        "        pred = torch.argmax(out)\n",
        "        if pred == labels[i]:\n",
        "          test_correct+=1\n",
        "        test_total+=1\n",
        "\n",
        "    test_accuracy = test_correct/test_total    \n",
        "  \n",
        "    print('epoch [{}/{}], training loss:{:.4f}, test accuracy:{:.4f}'.format(epoch+1, epochs, np.mean(loss_epoch), test_accuracy))\n",
        "################################################################################################################################\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "UPr25otiuHI7"
      },
      "outputs": [],
      "source": [
        "# download and load data\n",
        "batch_size = 256\n",
        "\n",
        "# download and transform train dataset\n",
        "train_loader = torch.utils.data.DataLoader(datasets.MNIST('./mnist_data', download=True, train=True, transform=transforms.Compose([\n",
        "                                                transforms.ToTensor(), # first, convert image to PyTorch tensor\n",
        "                                                transforms.Normalize((0.1307,), (0.3081,)) # normalize inputs\n",
        "                                                ])), batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# download and transform test dataset\n",
        "test_loader = torch.utils.data.DataLoader(datasets.MNIST('./mnist_data', download=True, train=False, transform=transforms.Compose([\n",
        "                                                              transforms.ToTensor(), # first, convert image to PyTorch tensor\n",
        "                                                              transforms.Normalize((0.1307,), (0.3081,)) # normalize inputs\n",
        "                                                          ])), batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIZLRLUIvpjY",
        "outputId": "c3f9ded4-94f2-4420-fdab-5d836a4b7265"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "# it is a good idea to take a look at the data. Here we see it is a 28x28 grayscale image\n",
        "for data, labels in train_loader:\n",
        "  print(data[0].size())\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EA5udFWDvs5X"
      },
      "outputs": [],
      "source": [
        "####                #### \n",
        "#### EDIT THIS CELL ####\n",
        "####                ####\n",
        "########################\n",
        "\n",
        "\n",
        "learning_rate = 0.001\n",
        "n_epochs = 10\n",
        "\n",
        "# neural network\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "    ### Define Layers\n",
        "    self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
        "    self.conv2 = nn.Conv2d(32, 64, 3, padding = 'valid')\n",
        "    self.conv3 = nn.Conv2d(64, 64, 3, padding = 'valid')\n",
        "    self.mp1 = nn.MaxPool2d(2)\n",
        "    self.fc1 = nn.Linear(1024, 64)\n",
        "    self.fc2 = nn.Linear(64, 10)\n",
        "    #self.mp1 = nn.MaxPool2d(2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.mp1(x)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.mp1(x)\n",
        "\n",
        "    x = self.conv3(x)\n",
        "    x = F.relu(x)\n",
        "\n",
        "    x = torch.flatten(x, 1)\n",
        "\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "\n",
        "    x = self.fc2(x)\n",
        "    x = F.softmax(x)\n",
        "    return x\n",
        "  \n",
        "# Every time you edit the neural network, you'll have to update this cell\n",
        "# Create model object\n",
        "model = NeuralNetwork().to(device)\n",
        "\n",
        "# Loads Adam optimizer, which implements a version of gradient descent\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uhYEua-v-iB",
        "outputId": "ea5da1b8-7a1e-412d-9190-cdd0ac0191ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NeuralNetwork(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n",
            "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n",
            "  (mp1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=1024, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Ravin\\AppData\\Local\\Temp\\ipykernel_6944\\4136183765.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  x = F.softmax(x)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[0.1051, 0.0962, 0.0928, 0.1013, 0.1149, 0.0970, 0.0925, 0.0917, 0.1136,\n",
              "         0.0948]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check the structure of your network\n",
        "print(model)\n",
        "\n",
        "# apply your model to a single input. This helps check that \n",
        "# the dimensions are correct\n",
        "model(torch.rand(1,1,28,28, device=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "C7CngzDTwB0k"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Ravin\\AppData\\Local\\Temp\\ipykernel_6944\\4136183765.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  x = F.softmax(x)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch [1/10], training loss:1.4717, test accuracy:0.9904\n",
            "epoch [2/10], training loss:1.4722, test accuracy:0.9871\n",
            "epoch [3/10], training loss:1.4718, test accuracy:0.9889\n",
            "epoch [4/10], training loss:1.4707, test accuracy:0.9905\n",
            "epoch [5/10], training loss:1.4703, test accuracy:0.9896\n",
            "epoch [6/10], training loss:1.4691, test accuracy:0.9903\n",
            "epoch [7/10], training loss:1.4691, test accuracy:0.9901\n",
            "epoch [8/10], training loss:1.4684, test accuracy:0.9910\n",
            "epoch [9/10], training loss:1.4688, test accuracy:0.9897\n",
            "epoch [10/10], training loss:1.4678, test accuracy:0.9917\n"
          ]
        }
      ],
      "source": [
        "train(10, model, train_loader, test_loader, optimizer, loss_function)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awZN5swx-Yn1"
      },
      "source": [
        "--------------\n",
        "                                                            Saving the model\n",
        "------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "14Yds8E_9tfT"
      },
      "outputs": [],
      "source": [
        "PATH = r'C:\\Users\\Ravin\\Desktop\\cs\\python\\courses\\maths_in_ai\\course_materials\\final_projects\\models\\model1.pth'\n",
        "torch.save(model.state_dict(), PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y96uYuJz-cjk"
      },
      "source": [
        "----------------------------------------\n",
        "                                                            Loading a model\n",
        "---------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_qukqdEq-cNK"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "NeuralNetwork(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n",
              "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n",
              "  (mp1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=1024, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = NeuralNetwork()\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = datasets.MNIST('./mnist_data', download=False, train=False, transform=transforms.Compose([\n",
        "                                                              transforms.ToTensor(), # first, convert image to PyTorch tensor\n",
        "                                                              transforms.Normalize((0.1307,), (0.3081,))]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7 "
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (64x16 and 1024x64)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\Ravin\\Desktop\\cs\\python\\courses\\maths_in_ai\\course_materials\\final_projects\\NeuralNetwork.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ravin/Desktop/cs/python/courses/maths_in_ai/course_materials/final_projects/NeuralNetwork.ipynb#ch0000011?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_trials):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ravin/Desktop/cs/python/courses/maths_in_ai/course_materials/final_projects/NeuralNetwork.ipynb#ch0000011?line=2'>3</a>\u001b[0m     \u001b[39mprint\u001b[39m(x[i][\u001b[39m1\u001b[39m],end\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Ravin/Desktop/cs/python/courses/maths_in_ai/course_materials/final_projects/NeuralNetwork.ipynb#ch0000011?line=3'>4</a>\u001b[0m     \u001b[39mprint\u001b[39m(torch\u001b[39m.\u001b[39margmax(model\u001b[39m.\u001b[39;49mforward(x[i][\u001b[39m0\u001b[39;49m])))\n",
            "\u001b[1;32mc:\\Users\\Ravin\\Desktop\\cs\\python\\courses\\maths_in_ai\\course_materials\\final_projects\\NeuralNetwork.ipynb Cell 12\u001b[0m in \u001b[0;36mNeuralNetwork.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ravin/Desktop/cs/python/courses/maths_in_ai/course_materials/final_projects/NeuralNetwork.ipynb#ch0000011?line=32'>33</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ravin/Desktop/cs/python/courses/maths_in_ai/course_materials/final_projects/NeuralNetwork.ipynb#ch0000011?line=34'>35</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflatten(x, \u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Ravin/Desktop/cs/python/courses/maths_in_ai/course_materials/final_projects/NeuralNetwork.ipynb#ch0000011?line=36'>37</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc1(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ravin/Desktop/cs/python/courses/maths_in_ai/course_materials/final_projects/NeuralNetwork.ipynb#ch0000011?line=37'>38</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ravin/Desktop/cs/python/courses/maths_in_ai/course_materials/final_projects/NeuralNetwork.ipynb#ch0000011?line=39'>40</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2(x)\n",
            "File \u001b[1;32mc:\\Users\\Ravin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32mc:\\Users\\Ravin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 103\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
            "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x16 and 1024x64)"
          ]
        }
      ],
      "source": [
        "num_trials = 20\n",
        "for i in range(num_trials):\n",
        "    print(x[i][1],end=' ')\n",
        "    print(torch.argmax(model.forward(x[i][0])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "NeuralNetwork",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "a58b0360702784b8c3e5d012f3d329b84ae744e0e81c9343b793c66187c3ad7b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
